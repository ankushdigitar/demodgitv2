<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width" initial-scale="1.0" />
    <title>Audio Test</title>

    <link rel="stylesheet" href="main.css" />
    <script src="https://cdn.auth0.com/js/auth0/9.16/auth0.min.js"></script>
    <script src="https://cdn.socket.io/4.2.0/socket.io.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/hark/1.2.0/hark.min.js"></script>
  </head>
  <body>
    <div class="container">
      <div class="ball-enclosure">
        <div class="ball"></div>
      </div>

      <div class="input-collector">
        <div class="inputs">
          <select id="rag">
            <option value="false" selected>Speak without document</option>
            <option value="true">Speak with document</option>
          </select>

          <select id="languageSelection">
            <option value="en" selected>English</option>
            <option value="ja">Japanese</option>
            <option value="hi">Hindi</option>
            <option value="pl">Polish</option>
          </select>

          <button id="toggleWebSocket" onclick="toggleWebSocket()">START SPEAKING</button>
        </div>

        <h1 id="webSocketStatus" class="token">Click on the Start Button to start speaking!</h1>
      </div>
    </div>

    <script>
      var tenantId = "";
      var ws;
      var mediaRecorder;
      var packetsSent = 0;
      var isSynthesisEnd = false;
      var currentResultID;
      let audioContext;
      let nextStartTime;
      let audioPlaying = false;
      let audioQueue = [];

      function toggleWebSocket() {
        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.close();
          if (audioContext) {
            audioContext.close();
          }
        } else {
          // Create a new AudioContext
          audioContext = new (window.AudioContext || window.webkitAudioContext)();
          nextStartTime = audioContext.currentTime;
          openWebSocket();
        }
      }

      function openWebSocket() {
        let urlParams = new URLSearchParams(window.location.search);
        let depUrl = urlParams.get("depUrl");

        if (!depUrl) {
          console.log("depUrl is not provided. Exiting...");
          return;
        }

        let language = document.getElementById("languageSelection").value;
        let rag = document.getElementById("rag").value;
        let encoding = "opuscat";
        let sampleRate = 8000;
        let remoteUrl =
          depUrl +
          "?language=" +
          encodeURIComponent(language) +
          "&rag=" +
          encodeURIComponent(rag) +
          "&encoding=" +
          encodeURIComponent(encoding) +
          "&sample_rate=" +
          encodeURIComponent(sampleRate);

        ws = new WebSocket(remoteUrl);
        //ws.binaryType = "arraybuffer";

        console.log("WebSocket URL:", remoteUrl);

        ws.onopen = function () {
          let button = document.getElementById("toggleWebSocket");
          button.textContent = "STOP SPEAKING";
          button.style.backgroundColor = "red";
          button.style.color = "white";
          document.getElementById("webSocketStatus").textContent = "";
          startRecording();
        };

        ws.onclose = function () {
          let button = document.getElementById("toggleWebSocket");
          button.textContent = "START SPEAKING";
          button.style.backgroundColor = "#2c3e50";
          button.style.color = "#fff";
          stopRecording();
          packetsSent = 0;
        };

        ws.onerror = function (error) {
          document.getElementById("webSocketStatus").textContent = "WebSocket encountered error: " + error;
          console.log("WebSocket encountered error:", error);
        };

        ws.onmessage = function (event) {
          const message = JSON.parse(event.data);
          if (message.type === "transcript") {
            console.log("Transcript received:", message.payload);
            document.getElementById("webSocketStatus").textContent = message.payload;
          } else if (message.type === "clear") {
            console.log("Clear received");
            audioQueue = [];
            ws.send(JSON.stringify({ event: "Mark" }));
            console.log("Audio queue cleared & mark sent for interruption acknowledgment.");
          } else if (message.type === "synthesis") {
            console.log("Synthesis received:", message);
            // Parse the JSON string and decode the base64 payload
            let resultId = message.resultId;
            let eventType = message.event;

            if (eventType === "synthesis_end") {
              isSynthesisEnd = true;
              console.log("Synthesis end received for resultId:", resultId);
              return;
            }

            let audioData;
            try {
              audioData = atob(message.payload);
            } catch (error) {
              console.error("Error parsing synthesis event:", error);
            }

            // Calculate the length of the ArrayBuffer
            let bufferLength = Math.floor(audioData.length / 4) * 4;

            // Convert the decoded base64 string to an ArrayBuffer
            let arrayBuffer = new ArrayBuffer(bufferLength);
            let view = new DataView(arrayBuffer);
            for (let i = 0; i < bufferLength; i++) {
              view.setUint8(i, audioData.charCodeAt(i));
            }

            // Push the ArrayBuffer to the queue
            audioQueue.push(arrayBuffer);
            // Try to play the audio in the queue
            handlePlaying(resultId);
          }
        };

        /*
            ws = io(remoteUrl, {
              query: "X-API-KEY=12345",
              transports: ["websocket"],
            });

            console.log("WebSocket URL:", remoteUrl);



            ws.on("connect", function () {
              let button = document.getElementById("toggleWebSocket");
              button.textContent = "STOP SPEAKING";
              button.style.backgroundColor = "red";
              button.style.color = "white";
              document.getElementById("webSocketStatus").textContent = "";
              startRecording();
            });

            ws.on("disconnect", function () {
              let button = document.getElementById("toggleWebSocket");
              button.textContent = "START SPEAKING";
              button.style.backgroundColor = "#2c3e50";
              button.style.color = "#fff";
              stopRecording();
              packetsSent = 0;
            });

            ws.on("connect_error", function (error) {
              document.getElementById("webSocketStatus").textContent = "WebSocket encountered error: " + error;
            });

            ws.on("transcript", function (event) {
              console.log("Transcript received:", event);
              document.getElementById("webSocketStatus").textContent = event;
            });

            ws.on("clear", function () {
              console.log("Clear received");
              audioQueue = [];
              ws.emit("message", JSON.stringify({ event: "Mark" }));
              console.log("Audio queue cleared & mark sent for interruption acknowledgment.");
            });

            ws.on("synthesis", function (event) {
              console.log("Synthesis received:", event);
              // Parse the JSON string and decode the base64 payload
              let resultId = event.synthesis.resultId;
              let eventType = event.event;

              if (eventType === "synthesis_end") {
                isSynthesisEnd = true;
                console.log("Synthesis end received for resultId:", resultId);
                return;
              }

              let audioData;
              try {
                audioData = atob(event.synthesis.payload);
              } catch (error) {
                console.error("Error parsing synthesis event:", error);
              }

              // Calculate the length of the ArrayBuffer
              let bufferLength = Math.floor(audioData.length / 4) * 4;

              // Convert the decoded base64 string to an ArrayBuffer
              let arrayBuffer = new ArrayBuffer(bufferLength);
              let view = new DataView(arrayBuffer);
              for (let i = 0; i < bufferLength; i++) {
                view.setUint8(i, audioData.charCodeAt(i));
              }

              // Push the ArrayBuffer to the queue
              audioQueue.push(arrayBuffer);
              // Try to play the audio in the queue
              handlePlaying(resultId);
            });*/
      }

      async function handlePlaying(resultId) {
        if (audioPlaying || !audioQueue.length) return; // If audio is already playing or queue is empty, do nothing
        audioPlaying = true; // Set flag to true

        let audioData = audioQueue.shift();
        if (audioData instanceof ArrayBuffer) {
          // Decode the audio data into an AudioBuffer
          let audioBuffer = await audioContext.decodeAudioData(audioData);
          let source = audioContext.createBufferSource();
          source.buffer = audioBuffer;

          // Connect the source to the context's destination (the speakers)
          source.connect(audioContext.destination);

          // Start the source now
          source.start(audioContext.currentTime);

          // When the source ends, play the next audio chunk
          source.onended = () => {
            audioPlaying = false; // Reset flag when audio ends
            handlePlaying(resultId); // Try to play next audio chunk in the queue
            if (audioQueue.length === 0 && isSynthesisEnd) {
              console.log("About to send MARK event.... PAY NOTE TO THIS MSG!! ");
              isSynthesisEnd = false;
              ws.send(JSON.stringify({ event: "Mark" }));
              console.log(`I sent MARK message. PAY NOTE TO THIS MSG!! ${JSON.stringify({ event: "Mark" })}`);
            }
          };
        } else {
          audioPlaying = false; // Reset flag when no audio data
        }
      }

      function startRecording() {
        const audioContext = new AudioContext();
        console.log(audioContext.sampleRate);

        navigator.mediaDevices
          .getUserMedia({ audio: true })
          .then((stream) => {
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.start(200);
            /** @type {Blob[]}
            mediaRecorder.ondataavailable = function (e) {
              console.log("Data available:", e.data);
              if (ws.readyState === WebSocket.OPEN) {
                ws.send(e.data);
                console.log("Packets would have been sent here:", packetsSent);
                packetsSent++;
              }
            };*/

            /** @type {base64} */
            mediaRecorder.ondataavailable = function (e) {
              //console.log("Data available:", e.data);
              if (ws.readyState === WebSocket.OPEN) {
                var reader = new FileReader();
                reader.onload = function () {
                  var base64data = reader.result.split(",")[1];
                  var json = JSON.stringify({ type: "audio", payload: base64data }); //JSON
                  console.log("Data available:", json);
                  var end = performance.now();
                  console.log("Time taken by FileReader:", end - start, "ms");
                  ws.send(json);
                  console.log("Packets would have been sent here:", packetsSent);
                  packetsSent++;
                };
                var start = performance.now();
                reader.readAsDataURL(e.data); //base64
              }
            };
          })
          .catch((error) => {
            console.error("Error getting audio stream:", error);
          });
      }

      function stopRecording() {
        if (mediaRecorder) {
          mediaRecorder.stop();
          audioQueue = [];
        }
      }
    </script>
  </body>
</html>
